#!/usr/bin/env python3
"""
07_correlation_analysis.py - An√°lise de Correla√ß√£o Sentimento x Varia√ß√£o de Pre√ßos

Calcula correla√ß√£o de Pearson entre scores de sentimento e varia√ß√£o de pre√ßos das a√ß√µes,
conforme especifica√ß√£o do trabalho.

Funcionalidades:
1. Carrega sentimentos (com e sem pr√©-processamento) do arquivo JSON
2. Carrega varia√ß√µes de pre√ßos do CSV
3. Calcula correla√ß√£o de Pearson
4. Gera visualiza√ß√µes (scatter plots, time series)
5. Salva resultados e estat√≠sticas
"""

import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import pearsonr
import os

# ---------- CONFIGURA√á√ÉO ----------
INPUT_SENTIMENT = "pipeline_output/06_sentiment/noticias_com_sentimentos.json"
INPUT_PRICES = "pipeline_output/04_fetch/noticias_com_precos_civis.csv"
OUTPUT_FOLDER = "pipeline_output/07_correlation"
OUTPUT_STATS = os.path.join(OUTPUT_FOLDER, "estatisticas_correlacao.txt")
OUTPUT_CSV = os.path.join(OUTPUT_FOLDER, "dados_completos.csv")

# Criar pasta de sa√≠da
os.makedirs(OUTPUT_FOLDER, exist_ok=True)

# Configura√ß√£o de estilo para gr√°ficos
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.size'] = 10

print(f"\n{'='*60}")
print("AN√ÅLISE DE CORRELA√á√ÉO: SENTIMENTO x VARIA√á√ÉO DE PRE√áOS")
print(f"{'='*60}\n")
print(f"Entrada sentimentos: {INPUT_SENTIMENT}")
print(f"Entrada pre√ßos: {INPUT_PRICES}")
print(f"Sa√≠da: {OUTPUT_FOLDER}\n")

# ---------- CARREGAR DADOS ----------

print("üìÇ Carregando dados de sentimento...")
with open(INPUT_SENTIMENT, 'r', encoding='utf-8') as f:
    noticias_sentiment = json.load(f)
print(f"‚úÖ {len(noticias_sentiment)} not√≠cias com sentimento carregadas\n")

print("üìÇ Carregando dados de pre√ßos...")
df_prices = pd.read_csv(INPUT_PRICES, encoding='utf-8', sep=';')
print(f"‚úÖ {len(df_prices)} registros de pre√ßos carregados\n")

# ---------- PREPARAR DADOS (JOIN mais robusto) ----------

print("üîÑ Preparando dados para an√°lise...")

# Normalizar sentimento para DataFrame
df_sent = pd.DataFrame(noticias_sentiment)

# Garantir colunas necess√°rias: data_publicacao como date, url (opcional)
if 'data_publicacao' in df_sent.columns:
    df_sent['data_publicacao'] = pd.to_datetime(df_sent['data_publicacao'], errors='coerce').dt.date
else:
    df_sent['data_publicacao'] = pd.NaT

# Normalizar pre√ßos
df_prices = df_prices.copy()
if 'data_publicacao' in df_prices.columns:
    df_prices['data_publicacao'] = pd.to_datetime(df_prices['data_publicacao'], errors='coerce').dt.date
else:
    df_prices['data_publicacao'] = pd.NaT

# Tenta jun√ß√£o pelo m√°ximo de robustez:
# 1) se houver URL em ambos, faz merge por empresa + url
# 2) sen√£o, merge por empresa + data_publicacao
has_url_sent = 'url' in df_sent.columns
has_url_prices = 'url' in df_prices.columns

if has_url_sent and has_url_prices:
    merged = pd.merge(
        df_sent,
        df_prices,
        how='left',
        left_on=['empresa', 'url'],
        right_on=['empresa', 'url'],
        suffixes=('_sent', '_price')
    )
else:
    merged = pd.merge(
        df_sent,
        df_prices,
        how='left',
        left_on=['empresa', 'data_publicacao'],
        right_on=['empresa', 'data_publicacao'],
        suffixes=('__sent', '_price')
    )

# Detec√ß√£o de colunas de varia√ß√£o de pre√ßo
# As colunas costumam vir como: d-2_pct_change_prev_close, d-1_pct_change_prev_close, d+0_pct_change_prev_close, etc.
price_variation_cols = [c for c in merged.columns if c.endswith('_pct_change_prev_close')]
variacoes_map = {}  # map: periodo -> coluna original
periodos = ['d-2', 'd-1', 'd+0', 'd+1', 'd+2']  # manter formato que deve aparecer no CSV
for col in price_variation_cols:
    # extrair o periodo do nome da coluna
    # exemplo: 'd-2_pct_change_prev_close' -> 'd-2'
    periodo = col.replace('_pct_change_prev_close', '')
    variacoes_map[periodo] = col

# Adicionar colunas padronizadas de varia√ß√£o
for periodo, col in variacoes_map.items():
    merged[f'variacao_{periodo}'] = merged[col]

# Selecionar apenas as colunas necess√°rias para o DataFrame final
variacao_columns_present = [f'variacao_{p}' for p in periodos if f'variacao_{p}' in merged.columns]
selected_cols = ['empresa', 'titulo', 'data_publicacao', 'sentimento_original', 'sentimento_preprocessado'] + variacao_columns_present

df = merged.reindex(columns=selected_cols)

# Tratar t√≠tulo caso n√£o exista
if 'titulo' not in df.columns:
    df['titulo'] = ''

# Filtrar not√≠cias com dados completos (sentimento + pre√ßos)
df_complete = df.dropna(subset=[c for c in df.columns if c.startswith('variacao_')], how='any')
print(f"‚úÖ {len(df_complete)} not√≠cias com dados completos (sentimento + pre√ßos)\n")

# Salvar dados unificados
df_complete.to_csv(OUTPUT_CSV, index=False, encoding='utf-8')
print(f"üíæ Dados completos salvos em: {OUTPUT_CSV}\n")

# ---------- AN√ÅLISE DE CORRELA√á√ÉO ----------

print(f"{'='*60}")
print("C√ÅLCULO DE CORRELA√á√ïES DE PEARSON")
print(f"{'='*60}\n")

# Colunas de varia√ß√£o de pre√ßo (as ones dispon√≠veis)
colunas_variacao = [col for col in df_complete.columns if col.startswith('variacao_')]

# Resultados de correla√ß√£o
resultados = []

with open(OUTPUT_STATS, 'w', encoding='utf-8') as f:
    f.write("="*60 + "\n")
    f.write("AN√ÅLISE DE CORRELA√á√ÉO: SENTIMENTO x VARIA√á√ÉO DE PRE√áOS\n")
    f.write("="*60 + "\n\n")

    # 1. Correla√ß√£o SENTIMENTO ORIGINAL vs VARIA√á√ïES
    f.write("1. SENTIMENTO ORIGINAL (sem pr√©-processamento)\n")
    f.write("-" * 60 + "\n\n")

    for col_var in colunas_variacao:
        mask = df_complete[col_var].notna()
        x = df_complete.loc[mask, 'sentimento_original']
        y = df_complete.loc[mask, col_var]

        if len(x) >= 3:
            corr, p_value = pearsonr(x, y)

            resultado = {
                'tipo': 'Original',
                'periodo': col_var,
                'correlacao': corr,
                'p_value': p_value,
                'n_amostras': len(x),
                'significativo': 'Sim' if p_value < 0.05 else 'N√£o'
            }
            resultados.append(resultado)

            f.write(f"  {col_var}:\n")
            f.write(f"    Correla√ß√£o de Pearson: {corr:.4f}\n")
            f.write(f"    P-valor: {p_value:.4f}\n")
            f.write(f"    Amostras: {len(x)}\n")
            f.write(f"    Significativo (p<0.05): {resultado['significativo']}\n\n")

    f.write("\n")

    # 2. Correla√ß√£o SENTIMENTO PR√â-PROCESSADO vs VARIA√á√ïES
    f.write("2. SENTIMENTO PR√â-PROCESSADO\n")
    f.write("-" * 60 + "\n\n")

    for col_var in colunas_variacao:
        mask = df_complete[col_var].notna()
        x = df_complete.loc[mask, 'sentimento_preprocessado']
        y = df_complete.loc[mask, col_var]

        if len(x) >= 3:
            corr, p_value = pearsonr(x, y)

            resultado = {
                'tipo': 'Pr√©-processado',
                'periodo': col_var,
                'correlacao': corr,
                'p_value': p_value,
                'n_amostras': len(x),
                'significativo': 'Sim' if p_value < 0.05 else 'N√£o'
            }
            resultados.append(resultado)

            f.write(f"  {col_var}:\n")
            f.write(f"    Correla√ß√£o de Pearson: {corr:.4f}\n")
            f.write(f"    P-valor: {p_value:.4f}\n")
            f.write(f"    Amostras: {len(x)}\n")
            f.write(f"    Significativo (p<0.05): {resultado['significativo']}\n\n")

    f.write("\n")
    f.write("="*60 + "\n")
    f.write("RESUMO\n")
    f.write("="*60 + "\n\n")

    # Resumo: melhores correla√ß√µes
    df_resultados = pd.DataFrame(resultados)

    f.write("MELHORES CORRELA√á√ïES (por valor absoluto):\n\n")
    if not df_resultados.empty:
        top_correlacoes = df_resultados.nlargest(5, 'correlacao', keep='all')
        for idx, row in top_correlacoes.iterrows():
            f.write(f"  {row['tipo']} - {row['periodo']}: {row['correlacao']:.4f} ")
            f.write(f"(p={row['p_value']:.4f}, n={row['n_amostras']})\n")
    else:
        f.write("Nenhuma correla√ß√£o significativa calculada.\n")

    f.write("\n")

    # M√©dia de correla√ß√µes por tipo
    if not df_resultados.empty:
        media_original = df_resultados[df_resultados['tipo'] == 'Original']['correlacao'].mean()
        media_prep = df_resultados[df_resultados['tipo'] == 'Pr√©-processado']['correlacao'].mean()
    else:
        media_original = float('nan')
        media_prep = float('nan')

    f.write(f"M√âDIA DE CORRELA√á√ïES:\n")
    f.write(f"  Original: {media_original:.4f}\n")
    f.write(f"  Pr√©-processado: {media_prep:.4f}\n\n")

    # Correla√ß√µes significativas
    if not df_resultados.empty:
        sig_original = len(df_resultados[(df_resultados['tipo'] == 'Original') & (df_resultados['p_value'] < 0.05)])
        sig_prep = len(df_resultados[(df_resultados['tipo'] == 'Pr√©-processado') & (df_resultados['p_value'] < 0.05)])
    else:
        sig_original = 0
        sig_prep = 0

    f.write(f"CORRELA√á√ïES SIGNIFICATIVAS (p<0.05):\n")
    f.write(f"  Original: {sig_original}/{len(colunas_variacao)}\n")
    f.write(f"  Pr√©-processado: {sig_prep}/{len(colunas_variacao)}\n\n")

print(f"üíæ Estat√≠sticas salvas em: {OUTPUT_STATS}\n")

# Imprimir resumo no console
print("RESUMO DAS CORRELALA√á√ïES:")
print("-" * 60)
if 'media_original' in locals() and 'media_prep' in locals():
    print(f"M√©dia de correla√ß√£o (Original): {media_original:.4f}")
    print(f"M√©dia de correla√ß√£o (Pr√©-processado): {media_prep:.4f}")
else:
    print("M√©dias n√£o dispon√≠veis (sem dados de correla√ß√£o).")
if 'sig_original' in locals() and 'sig_prep' in locals():
    print(f"Correla√ß√µes significativas (Original): {sig_original}/{len(colunas_variacao)}")
    print(f"Correla√ß√µes significativas (Pr√©-processado): {sig_prep}/{len(colunas_variacao)}\n")
else:
    print("Correla√ß√µes significativas n√£o dispon√≠veis.\n")

# ---------- VISUALIZA√á√ïES ----------

print(f"{'='*60}")
print("GERANDO VISUALIZA√á√ïES")
print(f"{'='*60}\n")

# 1. Scatter plot: Sentimento vs Varia√ß√£o D+1 (pr√≥ximo preg√£o)
print("üìä Gerando scatter plot (Sentimento vs Varia√ß√£o D+1)...")

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Original
mask = df_complete['variacao_d+1'].notna()
x_orig = df_complete.loc[mask, 'sentimento_original']
y_orig = df_complete.loc[mask, 'variacao_d+1']
corr_orig, p_orig = pearsonr(x_orig, y_orig) if len(x_orig) >= 3 else (0, 1)

axes[0].scatter(x_orig, y_orig, alpha=0.6, s=100, color='steelblue')
axes[0].set_xlabel('Sentimento Original', fontsize=12)
axes[0].set_ylabel('Varia√ß√£o de Pre√ßo D+1 (%)', fontsize=12)
axes[0].set_title(f'Original: r={corr_orig:.4f}, p={p_orig:.4f}', fontsize=14)
axes[0].grid(True, alpha=0.3)
axes[0].axhline(y=0, color='red', linestyle='--', alpha=0.5)
axes[0].axvline(x=0, color='red', linestyle='--', alpha=0.5)

# Pr√©-processado
x_prep = df_complete.loc[mask, 'sentimento_preprocessado']
y_prep = df_complete.loc[mask, 'variacao_d+1']
corr_prep, p_prep = pearsonr(x_prep, y_prep) if len(x_prep) >= 3 else (0, 1)

axes[1].scatter(x_prep, y_prep, alpha=0.6, s=100, color='darkorange')
axes[1].set_xlabel('Sentimento Pr√©-processado', fontsize=12)
axes[1].set_ylabel('Varia√ß√£o de Pre√ßo D+1 (%)', fontsize=12)
axes[1].set_title(f'Pr√©-processado: r={corr_prep:.4f}, p={p_prep:.4f}', fontsize=14)
axes[1].grid(True, alpha=0.3)
axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)
axes[1].axvline(x=0, color='red', linestyle='--', alpha=0.5)

plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_FOLDER, 'scatter_sentimento_vs_variacao_d+1.png'), dpi=300)
plt.close()
print("‚úÖ Scatter plot salvo\n")

# 2. Heatmap de correla√ß√µes
print("üìä Gerando heatmap de correla√ß√µes...")

# Preparar matriz de correla√ß√µes
periodos = ['d-2', 'd-1', 'd+0', 'd+1', 'd+2']
matriz_corr = np.zeros((2, len(periodos)))

for i, periodo in enumerate(periodos):
    col = f'variacao_{periodo}'
    if col in df_complete.columns:
        mask = df_complete[col].notna()

        # Original
        if len(df_complete.loc[mask, 'sentimento_original']) >= 3:
            corr_orig, _ = pearsonr(df_complete.loc[mask, 'sentimento_original'], df_complete.loc[mask, col])
            matriz_corr[0, i] = corr_orig

        # Pr√©-processado
        if len(df_complete.loc[mask, 'sentimento_preprocessado']) >= 3:
            corr_prep, _ = pearsonr(df_complete.loc[mask, 'sentimento_preprocessado'], df_complete.loc[mask, col])
            matriz_corr[1, i] = corr_prep

fig, ax = plt.subplots(figsize=(10, 4))
sns.heatmap(matriz_corr, annot=True, fmt='.4f', cmap='RdYlGn', center=0,
            xticklabels=periodos, yticklabels=['Original', 'Pr√©-processado'],
            cbar_kws={'label': 'Correla√ß√£o de Pearson'})
ax.set_title('Correla√ß√µes: Sentimento x Varia√ß√£o de Pre√ßos por Per√≠odo', fontsize=14)
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_FOLDER, 'heatmap_correlacoes.png'), dpi=300)
plt.close()
print("‚úÖ Heatmap salvo\n")

# 3. Gr√°fico de barras: compara√ß√£o de correla√ß√µes
print("üìä Gerando gr√°fico de barras (compara√ß√£o)...")

fig, ax = plt.subplots(figsize=(12, 6))
x_pos = np.arange(len(periodos))
width = 0.35

corr_original = matriz_corr[0, :]
corr_prep = matriz_corr[1, :]

bars1 = ax.bar(x_pos - width/2, corr_original, width, label='Original', color='steelblue', alpha=0.8)
bars2 = ax.bar(x_pos + width/2, corr_prep, width, label='Pr√©-processado', color='darkorange', alpha=0.8)

ax.set_xlabel('Per√≠odo', fontsize=12)
ax.set_ylabel('Correla√ß√£o de Pearson', fontsize=12)
ax.set_title('Compara√ß√£o de Correla√ß√µes: Original vs Pr√©-processado', fontsize=14)
ax.set_xticks(x_pos)
ax.set_xticklabels(periodos)
ax.legend()
ax.grid(True, alpha=0.3, axis='y')
ax.axhline(y=0, color='black', linestyle='-', linewidth=0.8)

plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_FOLDER, 'barras_comparacao_correlacoes.png'), dpi=300)
plt.close()
print("‚úÖ Gr√°fico de barras salvo\n")

# 4. Box plot: distribui√ß√£o de sentimentos por empresa
print("üìä Gerando box plots (distribui√ß√£o por empresa)...")

fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# Original
df_complete.boxplot(column='sentimento_original', by='empresa', ax=axes[0])
axes[0].set_title('Distribui√ß√£o de Sentimento Original por Empresa', fontsize=12)
axes[0].set_xlabel('Empresa', fontsize=11)
axes[0].set_ylabel('Sentimento', fontsize=11)
axes[0].get_figure().suptitle('')  # Remove t√≠tulo autom√°tico

# Pr√©-processado
df_complete.boxplot(column='sentimento_preprocessado', by='empresa', ax=axes[1])
axes[1].set_title('Distribui√ß√£o de Sentimento Pr√©-processado por Empresa', fontsize=12)
axes[1].set_xlabel('Empresa', fontsize=11)
axes[1].set_ylabel('Sentimento', fontsize=11)
axes[1].get_figure().suptitle('')  # Remove t√≠tulo autom√°tico

plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_FOLDER, 'boxplot_sentimento_por_empresa.png'), dpi=300)
plt.close()
print("‚úÖ Box plots salvos\n")

# ---------- FINALIZA√á√ÉO ----------

print(f"{'='*60}")
print("‚úÖ AN√ÅLISE DE CORRELA√á√ÉO CONCLU√çDA!")
print(f"{'='*60}\n")
print("Arquivos gerados:")
print(f"  - {OUTPUT_STATS}")
print(f"  - {OUTPUT_CSV}")
print(f"  - {OUTPUT_FOLDER}/scatter_sentimento_vs_variacao_d+1.png")
print(f"  - {OUTPUT_FOLDER}/heatmap_correlacoes.png")
print(f"  - {OUTPUT_FOLDER}/barras_comparacao_correlacoes.png")
print(f"  - {OUTPUT_FOLDER}/boxplot_sentimento_por_empresa.png")
print()